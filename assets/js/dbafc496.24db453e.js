"use strict";(self.webpackChunkotai_documentation=self.webpackChunkotai_documentation||[]).push([[3660],{1309:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"tutorials/text-to-speech/openai-edge-tts-integration","title":"\ud83d\udde8\ufe0f Edge TTS Using Docker","description":"This tutorial is a community contribution and is not supported by the Open WebUI team. It serves only as a demonstration on how to customize Open WebUI for your specific use case. Want to contribute? Check out the contributing tutorial.","source":"@site/docs/tutorials/text-to-speech/openai-edge-tts-integration.md","sourceDirName":"tutorials/text-to-speech","slug":"/tutorials/text-to-speech/openai-edge-tts-integration","permalink":"/open-tutor-ai-docs/docs/tutorials/text-to-speech/openai-edge-tts-integration","draft":false,"unlisted":false,"editUrl":"https://github.com/pr-elhajji/open-tutor-ai-CE/docs/tutorials/text-to-speech/openai-edge-tts-integration.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"\ud83d\udde8\ufe0f Edge TTS Using Docker"},"sidebar":"tutorialSidebar","previous":{"title":"\ud83d\udde8\ufe0f Text-to-Speech","permalink":"/open-tutor-ai-docs/docs/category/\ufe0f-text-to-speech"},"next":{"title":"\ud83d\udde8\ufe0f Kokoro-FastAPI Using Docker","permalink":"/open-tutor-ai-docs/docs/tutorials/text-to-speech/Kokoro-FastAPI-integration"}}');var s=t(4848),o=t(8453);const r={sidebar_position:1,title:"\ud83d\udde8\ufe0f Edge TTS Using Docker"},a="Integrating openai-edge-tts \ud83d\udde3\ufe0f with Open WebUI",d={},l=[{value:"What is <code>openai-edge-tts</code>?",id:"what-is-openai-edge-tts",level:2},{value:"Requirements",id:"requirements",level:2},{value:"\u26a1\ufe0f Quick start",id:"\ufe0f-quick-start",level:2},{value:"Setting up Open WebUI to use <code>openai-edge-tts</code>",id:"setting-up-open-webui-to-use-openai-edge-tts",level:2},{value:"\ud83d\udc0d Running with Python",id:"-running-with-python",level:3},{value:"1. Clone the Repository",id:"1-clone-the-repository",level:4},{value:"2. Set Up a Virtual Environment",id:"2-set-up-a-virtual-environment",level:4},{value:"3. Install Dependencies",id:"3-install-dependencies",level:4},{value:"4. Configure Environment Variables",id:"4-configure-environment-variables",level:4},{value:"5. Run the Server",id:"5-run-the-server",level:4},{value:"6. Test the API",id:"6-test-the-api",level:4},{value:"Endpoint: <code>/v1/audio/speech</code> (aliased with <code>/audio/speech</code>)",id:"endpoint-v1audiospeech-aliased-with-audiospeech",level:5},{value:"Additional Endpoints",id:"additional-endpoints",level:5},{value:"\ud83d\udc33 Quick Config for Docker",id:"-quick-config-for-docker",level:2},{value:"Additional Resources",id:"additional-resources",level:2},{value:"\ud83c\udf99\ufe0f Voice Samples",id:"\ufe0f-voice-samples",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",h5:"h5",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsx)(n.p,{children:"This tutorial is a community contribution and is not supported by the Open WebUI team. It serves only as a demonstration on how to customize Open WebUI for your specific use case. Want to contribute? Check out the contributing tutorial."})}),"\n",(0,s.jsx)(n.header,{children:(0,s.jsxs)(n.h1,{id:"integrating-openai-edge-tts-\ufe0f-with-open-webui",children:["Integrating ",(0,s.jsx)(n.code,{children:"openai-edge-tts"})," \ud83d\udde3\ufe0f with Open WebUI"]})}),"\n",(0,s.jsxs)(n.h2,{id:"what-is-openai-edge-tts",children:["What is ",(0,s.jsx)(n.code,{children:"openai-edge-tts"}),"?"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://github.com/travisvn/openai-edge-tts",children:"OpenAI Edge TTS"})," is a text-to-speech API that mimics the OpenAI API endpoint, allowing for a direct substitute in scenarios where you can define the endpoint URL, like with Open WebUI."]}),"\n",(0,s.jsxs)(n.p,{children:["It uses the ",(0,s.jsx)(n.a,{href:"https://github.com/rany2/edge-tts",children:"edge-tts"}),' package, which leverages the Edge browser\'s free "Read Aloud" feature to emulate a request to Microsoft / Azure in order to receive very high quality text-to-speech for free.']}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://tts.travisvn.com",children:"Sample the voices here"})}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"How is it different from 'openedai-speech'?"}),(0,s.jsxs)(n.p,{children:["Similar to ",(0,s.jsx)(n.a,{href:"https://github.com/matatonic/openedai-speech",children:"openedai-speech"}),", ",(0,s.jsx)(n.a,{href:"https://github.com/travisvn/openai-edge-tts",children:"openai-edge-tts"})," is a text-to-speech API endpoint that mimics the OpenAI API endpoint, allowing for a direct substitute in scenarios where the OpenAI Speech endpoint is callable and the server endpoint URL can be configured."]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"openedai-speech"})," is a more comprehensive option that allows for entirely offline generation of speech with many modalities to choose from."]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"openai-edge-tts"})," is a simpler option that uses a Python package called ",(0,s.jsx)(n.code,{children:"edge-tts"})," to generate the audio."]})]}),"\n",(0,s.jsx)(n.h2,{id:"requirements",children:"Requirements"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Docker installed on your system"}),"\n",(0,s.jsx)(n.li,{children:"Open WebUI running"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"\ufe0f-quick-start",children:"\u26a1\ufe0f Quick start"}),"\n",(0,s.jsx)(n.p,{children:"The simplest way to get started without having to configure anything is to run the command below"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker run -d -p 5050:5050 travisvn/openai-edge-tts:latest\n"})}),"\n",(0,s.jsx)(n.p,{children:"This will run the service at port 5050 with all the default configs"}),"\n",(0,s.jsxs)(n.h2,{id:"setting-up-open-webui-to-use-openai-edge-tts",children:["Setting up Open WebUI to use ",(0,s.jsx)(n.code,{children:"openai-edge-tts"})]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Open the Admin Panel and go to ",(0,s.jsx)(n.code,{children:"Settings"})," -> ",(0,s.jsx)(n.code,{children:"Audio"})]}),"\n",(0,s.jsx)(n.li,{children:"Set your TTS Settings to match the screenshot below"}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.em,{children:"Note: you can specify the TTS Voice here"})}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://utfs.io/f/MMMHiQ1TQaBobmOhsMkrO6Tl2kxX39dbuFiQ8cAoNzysIt7f",alt:"Screenshot of Open WebUI Admin Settings for Audio adding the correct endpoints for this project"})}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["The default API key is the string ",(0,s.jsx)(n.code,{children:"your_api_key_here"}),". You do not have to change that value if you do not need the added security."]})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"And that's it! You can end here"})}),"\n",(0,s.jsxs)(n.h1,{id:"please-\ufe0f-star-the-repo-on-github-if-you-find-openai-edge-tts-useful",children:["Please \u2b50\ufe0f star the repo on GitHub if you find ",(0,s.jsx)(n.a,{href:"https://github.com/travisvn/openai-edge-tts",children:"OpenAI Edge TTS"})," useful"]}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"Running with Python"}),(0,s.jsx)(n.h3,{id:"-running-with-python",children:"\ud83d\udc0d Running with Python"}),(0,s.jsx)(n.p,{children:"If you prefer to run this project directly with Python, follow these steps to set up a virtual environment, install dependencies, and start the server."}),(0,s.jsx)(n.h4,{id:"1-clone-the-repository",children:"1. Clone the Repository"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/travisvn/openai-edge-tts.git\ncd openai-edge-tts\n"})}),(0,s.jsx)(n.h4,{id:"2-set-up-a-virtual-environment",children:"2. Set Up a Virtual Environment"}),(0,s.jsx)(n.p,{children:"Create and activate a virtual environment to isolate dependencies:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"# For macOS/Linux\npython3 -m venv venv\nsource venv/bin/activate\n\n# For Windows\npython -m venv venv\nvenv\\Scripts\\activate\n"})}),(0,s.jsx)(n.h4,{id:"3-install-dependencies",children:"3. Install Dependencies"}),(0,s.jsxs)(n.p,{children:["Use ",(0,s.jsx)(n.code,{children:"pip"})," to install the required packages listed in ",(0,s.jsx)(n.code,{children:"requirements.txt"}),":"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install -r requirements.txt\n"})}),(0,s.jsx)(n.h4,{id:"4-configure-environment-variables",children:"4. Configure Environment Variables"}),(0,s.jsxs)(n.p,{children:["Create a ",(0,s.jsx)(n.code,{children:".env"})," file in the root directory and set the following variables:"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-plaintext",children:"API_KEY=your_api_key_here\nPORT=5050\n\nDEFAULT_VOICE=en-US-AvaNeural\nDEFAULT_RESPONSE_FORMAT=mp3\nDEFAULT_SPEED=1.0\n\nDEFAULT_LANGUAGE=en-US\n\nREQUIRE_API_KEY=True\nREMOVE_FILTER=False\nEXPAND_API=True\n"})}),(0,s.jsx)(n.h4,{id:"5-run-the-server",children:"5. Run the Server"}),(0,s.jsx)(n.p,{children:"Once configured, start the server with:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python app/server.py\n"})}),(0,s.jsxs)(n.p,{children:["The server will start running at ",(0,s.jsx)(n.code,{children:"http://localhost:5050"}),"."]}),(0,s.jsx)(n.h4,{id:"6-test-the-api",children:"6. Test the API"}),(0,s.jsxs)(n.p,{children:["You can now interact with the API at ",(0,s.jsx)(n.code,{children:"http://localhost:5050/v1/audio/speech"})," and other available endpoints. See the Usage section for request examples."]})]}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"Usage details"}),(0,s.jsxs)(n.h5,{id:"endpoint-v1audiospeech-aliased-with-audiospeech",children:["Endpoint: ",(0,s.jsx)(n.code,{children:"/v1/audio/speech"})," (aliased with ",(0,s.jsx)(n.code,{children:"/audio/speech"}),")"]}),(0,s.jsx)(n.p,{children:"Generates audio from the input text. Available parameters:"}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Required Parameter:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"input"})," (string): The text to be converted to audio (up to 4096 characters)."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Optional Parameters:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"model"}),' (string): Set to "tts-1" or "tts-1-hd" (default: ',(0,s.jsx)(n.code,{children:'"tts-1"'}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"voice"})," (string): One of the OpenAI-compatible voices (alloy, echo, fable, onyx, nova, shimmer) or any valid ",(0,s.jsx)(n.code,{children:"edge-tts"})," voice (default: ",(0,s.jsx)(n.code,{children:'"en-US-AvaNeural"'}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"response_format"})," (string): Audio format. Options: ",(0,s.jsx)(n.code,{children:"mp3"}),", ",(0,s.jsx)(n.code,{children:"opus"}),", ",(0,s.jsx)(n.code,{children:"aac"}),", ",(0,s.jsx)(n.code,{children:"flac"}),", ",(0,s.jsx)(n.code,{children:"wav"}),", ",(0,s.jsx)(n.code,{children:"pcm"})," (default: ",(0,s.jsx)(n.code,{children:"mp3"}),")."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"speed"})," (number): Playback speed (0.25 to 4.0). Default is ",(0,s.jsx)(n.code,{children:"1.0"}),"."]}),"\n"]}),(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsxs)(n.p,{children:["You can browse available voices and listen to sample previews at ",(0,s.jsx)(n.a,{href:"https://tts.travisvn.com",children:"tts.travisvn.com"})]})}),(0,s.jsxs)(n.p,{children:["Example request with ",(0,s.jsx)(n.code,{children:"curl"})," and saving the output to an mp3 file:"]}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:5050/v1/audio/speech \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer your_api_key_here" \\\n  -d \'{\n    "input": "Hello, I am your AI assistant! Just let me know how I can help bring your ideas to life.",\n    "voice": "echo",\n    "response_format": "mp3",\n    "speed": 1.0\n  }\' \\\n  --output speech.mp3\n'})}),(0,s.jsx)(n.p,{children:"Or, to be in line with the OpenAI API endpoint parameters:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:5050/v1/audio/speech \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer your_api_key_here" \\\n  -d \'{\n    "model": "tts-1",\n    "input": "Hello, I am your AI assistant! Just let me know how I can help bring your ideas to life.",\n    "voice": "alloy"\n  }\' \\\n  --output speech.mp3\n'})}),(0,s.jsx)(n.p,{children:"And an example of a language other than English:"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST http://localhost:5050/v1/audio/speech \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer your_api_key_here" \\\n  -d \'{\n    "model": "tts-1",\n    "input": "\u3058\u3083\u3042\u3001\u884c\u304f\u3002\u96fb\u8eca\u306e\u6642\u9593\u3001\u8abf\u3079\u3066\u304a\u304f\u3088\u3002",\n    "voice": "ja-JP-KeitaNeural"\n  }\' \\\n  --output speech.mp3\n'})}),(0,s.jsx)(n.h5,{id:"additional-endpoints",children:"Additional Endpoints"}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"POST/GET /v1/models"}),": Lists available TTS models."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"POST/GET /v1/voices"}),": Lists ",(0,s.jsx)(n.code,{children:"edge-tts"})," voices for a given language / locale."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"POST/GET /v1/voices/all"}),": Lists all ",(0,s.jsx)(n.code,{children:"edge-tts"})," voices, with language support information."]}),"\n"]}),(0,s.jsxs)(n.admonition,{type:"info",children:[(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"/v1"})," is now optional."]}),(0,s.jsxs)(n.p,{children:["Additionally, there are endpoints for ",(0,s.jsx)(n.strong,{children:"Azure AI Speech"})," and ",(0,s.jsx)(n.strong,{children:"ElevenLabs"})," for potential future support if custom API endpoints are allowed for these options in Open WebUI."]}),(0,s.jsxs)(n.p,{children:["These can be disabled by setting the environment variable ",(0,s.jsx)(n.code,{children:"EXPAND_API=False"}),"."]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"-quick-config-for-docker",children:"\ud83d\udc33 Quick Config for Docker"}),"\n",(0,s.jsx)(n.p,{children:"You can configure the environment variables in the command used to run the project"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"docker run -d -p 5050:5050 \\\n  -e API_KEY=your_api_key_here \\\n  -e PORT=5050 \\\n  -e DEFAULT_VOICE=en-US-AvaNeural \\\n  -e DEFAULT_RESPONSE_FORMAT=mp3 \\\n  -e DEFAULT_SPEED=1.0 \\\n  -e DEFAULT_LANGUAGE=en-US \\\n  -e REQUIRE_API_KEY=True \\\n  -e REMOVE_FILTER=False \\\n  -e EXPAND_API=True \\\n  travisvn/openai-edge-tts:latest\n"})}),"\n",(0,s.jsxs)(n.admonition,{type:"note",children:[(0,s.jsx)(n.p,{children:"The markdown text is now put through a filter for enhanced readability and support."}),(0,s.jsxs)(n.p,{children:["You can disable this by setting the environment variable ",(0,s.jsx)(n.code,{children:"REMOVE_FILTER=True"}),"."]})]}),"\n",(0,s.jsx)(n.h2,{id:"additional-resources",children:"Additional Resources"}),"\n",(0,s.jsxs)(n.p,{children:["For more information on ",(0,s.jsx)(n.code,{children:"openai-edge-tts"}),", you can visit the ",(0,s.jsx)(n.a,{href:"https://github.com/travisvn/openai-edge-tts",children:"GitHub repo"})]}),"\n",(0,s.jsxs)(n.p,{children:["For direct support, you can visit the ",(0,s.jsx)(n.a,{href:"https://tts.travisvn.com/discord",children:"Voice AI & TTS Discord"})]}),"\n",(0,s.jsx)(n.h2,{id:"\ufe0f-voice-samples",children:"\ud83c\udf99\ufe0f Voice Samples"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://tts.travisvn.com/",children:"Play voice samples and see all available Edge TTS voices"})})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>a});var i=t(6540);const s={},o=i.createContext(s);function r(e){const n=i.useContext(o);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);