"use strict";(self.webpackChunkotai_documentation=self.webpackChunkotai_documentation||[]).push([[9426],{2184:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"getting-started/quick-start/tab-docker/DockerSwarm","title":"DockerSwarm","description":"Docker Swarm","source":"@site/docs/getting-started/quick-start/tab-docker/DockerSwarm.md","sourceDirName":"getting-started/quick-start/tab-docker","slug":"/getting-started/quick-start/tab-docker/DockerSwarm","permalink":"/open-tutor-ai-docs/docs/getting-started/quick-start/tab-docker/DockerSwarm","draft":false,"unlisted":false,"editUrl":"https://github.com/pr-elhajji/open-tutor-ai-CE/docs/getting-started/quick-start/tab-docker/DockerSwarm.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Docker Compose Setup","permalink":"/open-tutor-ai-docs/docs/getting-started/quick-start/tab-docker/DockerCompose"},"next":{"title":"DockerUpdating","permalink":"/open-tutor-ai-docs/docs/getting-started/quick-start/tab-docker/DockerUpdating"}}');var a=t(4848),o=t(8453);const s={},i=void 0,c={},l=[{value:"Docker Swarm",id:"docker-swarm",level:2},{value:"Docker-stack.yaml",id:"docker-stackyaml",level:4}];function d(e){const n={a:"a",code:"code",em:"em",h2:"h2",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h2,{id:"docker-swarm",children:"Docker Swarm"}),"\n",(0,a.jsx)(n.p,{children:"This installation method requires knowledge on Docker Swarms, as it utilizes a stack file to deploy 3 seperate containers as services in a Docker Swarm."}),"\n",(0,a.jsxs)(n.p,{children:["It includes isolated containers of ChromaDB, Ollama, and OpenTutorAI.\nAdditionally, there are pre-filled ",(0,a.jsx)(n.a,{href:"/getting-started/env-configuration",children:"Environment Variables"})," to further illustrate the setup."]}),"\n",(0,a.jsx)(n.p,{children:"Choose the appropriate command based on your hardware setup:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Before Starting"}),":"]}),"\n",(0,a.jsx)(n.p,{children:"Directories for your volumes need to be created on the host, or you can specify a custom location or volume."}),"\n",(0,a.jsxs)(n.p,{children:["The current example utilizes an isolated dir ",(0,a.jsx)(n.code,{children:"data"}),", which is within the same dir as the ",(0,a.jsx)(n.code,{children:"docker-stack.yaml"}),"."]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"For example"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"mkdir -p data/open-webui data/chromadb data/ollama\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"With GPU Support"}),":"]}),"\n",(0,a.jsx)(n.h4,{id:"docker-stackyaml",children:"Docker-stack.yaml"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'version: \'3.9\'\n\nservices:\n  openTutorAI:\n    image: ghcr.io/open-webui/open-webui:main\n    depends_on:\n        - chromadb\n        - ollama\n    volumes:\n      - ./data/open-webui:/app/backend/data\n    environment:\n      DATA_DIR: /app/backend/data \n      OLLAMA_BASE_URLS: http://ollama:11434\n      CHROMA_HTTP_PORT: 8000\n      CHROMA_HTTP_HOST: chromadb\n      CHROMA_TENANT: default_tenant\n      VECTOR_DB: chroma\n      WEBUI_NAME: Awesome ChatBot\n      CORS_ALLOW_ORIGIN: "*" # This is the current Default, will need to change before going live\n      RAG_EMBEDDING_ENGINE: ollama\n      RAG_EMBEDDING_MODEL: nomic-embed-text-v1.5\n      RAG_EMBEDDING_MODEL_TRUST_REMOTE_CODE: "True"\n    ports:\n      - target: 8080\n        published: 8080\n        mode: overlay\n    deploy:\n      replicas: 1\n      restart_policy:\n        condition: any\n        delay: 5s\n        max_attempts: 3\n\n  chromadb:\n    hostname: chromadb\n    image: chromadb/chroma:0.5.15\n    volumes:\n      - ./data/chromadb:/chroma/chroma\n    environment:\n      - IS_PERSISTENT=TRUE\n      - ALLOW_RESET=TRUE\n      - PERSIST_DIRECTORY=/chroma/chroma\n    ports: \n      - target: 8000\n        published: 8000\n        mode: overlay\n    deploy:\n      replicas: 1\n      restart_policy:\n        condition: any\n        delay: 5s\n        max_attempts: 3\n    healthcheck: \n      test: ["CMD-SHELL", "curl localhost:8000/api/v1/heartbeat || exit 1"]\n      interval: 10s\n      retries: 2\n      start_period: 5s\n      timeout: 10s\n\n  ollama:\n    image: ollama/ollama:latest\n    hostname: ollama\n    ports:\n      - target: 11434\n        published: 11434\n        mode: overlay\n    deploy:\n      resources:\n        reservations:\n          generic_resources:\n            - discrete_resource_spec:\n                kind: "NVIDIA-GPU"\n                value: 0\n      replicas: 1\n      restart_policy:\n        condition: any\n        delay: 5s\n        max_attempts: 3\n    volumes:\n      - ./data/ollama:/root/.ollama\n\n'})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Additional Requirements"}),":"]}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:"Ensure CUDA is Enabled, follow your OS and GPU instructions for that."}),"\n",(0,a.jsxs)(n.li,{children:["Enable Docker GPU support, see ",(0,a.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html",title:" on Nvidia's site.",children:"Nvidia Container Toolkit"})]}),"\n",(0,a.jsxs)(n.li,{children:["Follow the ",(0,a.jsx)(n.a,{href:"https://gist.github.com/tomlankhorst/33da3c4b9edbde5c83fc1244f010815c#configuring-docker-to-work-with-your-gpus",children:"Guide here on configuring Docker Swarm to with with your GPU"})]}),"\n"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Ensure ",(0,a.jsx)(n.em,{children:"GPU Resource"})," is enabled in ",(0,a.jsx)(n.code,{children:"/etc/nvidia-container-runtime/config.toml"})," and enable GPU resource advertising by uncommenting the ",(0,a.jsx)(n.code,{children:'swarm-resource = "DOCKER_RESOURCE_GPU"'}),". The docker daemon must be restarted after updating these files on each node."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"With CPU Support"}),":"]}),"\n",(0,a.jsxs)(n.p,{children:["Modify the Ollama Service within ",(0,a.jsx)(n.code,{children:"docker-stack.yaml"})," and remove the lines for ",(0,a.jsx)(n.code,{children:"generic_resources:"})]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"    ollama:\n  image: ollama/ollama:latest\n  hostname: ollama\n  ports:\n    - target: 11434\n      published: 11434\n      mode: overlay\n  deploy:\n    replicas: 1\n    restart_policy:\n      condition: any\n      delay: 5s\n      max_attempts: 3\n  volumes:\n    - ./data/ollama:/root/.ollama\n"})}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Deploy Docker Stack"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker stack deploy -c docker-stack.yaml -d super-awesome-ai\n"})}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>s,x:()=>i});var r=t(6540);const a={},o=r.createContext(a);function s(e){const n=r.useContext(o);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),r.createElement(o.Provider,{value:n},e.children)}}}]);